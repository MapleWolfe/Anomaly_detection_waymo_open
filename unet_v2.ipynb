{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model Implementation\n",
    "\n",
    "## Data Gathering and Augmentation\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Library Imports\n",
    "import os\n",
    "import time\n",
    "from io import BytesIO\n",
    "import random\n",
    "\n",
    "#Third party imports\n",
    "from google.cloud import storage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.functional import pad\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import ipyplot\n",
    "\n",
    "import altair\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#Local application imports\n",
    "from transforms import (\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    "    normalize,\n",
    "    gaussian_smoothing,\n",
    "    image_histogram_equalization\n",
    ")\n",
    "\n",
    "import build_unet\n",
    "\n",
    "from helper import (\n",
    "    dice_loss,\n",
    "    custom_collate,\n",
    "    analyze_num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing data from Google bucket\n",
    "First, we want to set up credentials and the client. The Waymo dataset isn't publicly open for use without permissions. Permissions were required for transfer of bucket information from Waymo google cloud services to our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file paths used will be relative\n",
    "google_application_credentials = 'food-V2.json' #replace this string with your own credentials\n",
    "bucket_name = 'waymo_perception_data' #you need to name your bucket\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_application_credentials\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we iterate through two different folders of information. One being the camera images and the other being the segmented image. For memory ease, we only iterate through one file at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab data for iterative training\n",
    "def grab_data_image():\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "  blobs_image = list(bucket.list_blobs(prefix='training/camera_image/'))\n",
    "\n",
    "  for blob1 in blobs_image:\n",
    "    object_name_image = blob1.name[len('training/camera_image/'):]\n",
    "\n",
    "    print(\"Loading in \", blob1)\n",
    "\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob1.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "  \n",
    "    #Yield results for iterative training  \n",
    "    yield df\n",
    "\n",
    "# Grab data for iterative training\n",
    "def grab_data_segment():\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "  blobs_segment = list(bucket.list_blobs(prefix='training/camera_segmentation/'))\n",
    "\n",
    "  for blob2 in blobs_segment:\n",
    "    object_name = blob2.name[len('training/camera_segmentation/'):]\n",
    "\n",
    "    print(\"Loading in \", blob2)\n",
    "\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob2.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "    \n",
    "    #Yield results for iterative training  \n",
    "    yield df\n",
    "\n",
    "#--------This one will be important for hyperparameter tuning ---------\n",
    "def grab_data(folder_name = 'training/camera_image/', max_parquet = 3):\n",
    "\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "  blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "  #random.Random(random_seed).shuffle(blobs)\n",
    "  i = -1\n",
    "  for blob in blobs:\n",
    "    i += 1\n",
    "    object_name = blob.name[len(folder_name):]\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "    if df_temp.empty:\n",
    "      df_temp = df\n",
    "    else:\n",
    "      df_temp = pd.concat([df_temp,df])\n",
    "    if i == max_parquet :\n",
    "      break\n",
    "\n",
    "  return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Data\n",
    "Firstly, we want to define a class that allows us to transform out current data into a pytorch related format, configured with transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataSet(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 inputs: list,\n",
    "                 targets: list,\n",
    "                 transform=None\n",
    "                 ):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    index: int):\n",
    "        # Select the sample\n",
    "        input_ID = self.inputs[index]\n",
    "        target_ID = self.targets[index]\n",
    "\n",
    "        # Load input and target\n",
    "        x = np.array(Image.open(BytesIO(input_ID)))\n",
    "        y = np.array(Image.open(BytesIO(target_ID)))\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "\n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply a pipeline of transformations to the training data. This is to help prevent data leakage, as well as streamline our process. We resize the images to be smaller in order to prevent any memory issues when developing our model. Due the size of our dataset and varying images previewed, we decided against further augmentation of the data. \n",
    "Augmentation would be considered if the original dataset were smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "transforms = ComposeDouble([\n",
    "    #Turn to grayscale\n",
    "    FunctionWrapperDouble(skimage.color.rgb2gray,input=True,target=False),\n",
    "    #Resizing\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(640, 960),\n",
    "                          anti_aliasing=True,\n",
    "                          preserve_range=True),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(640, 960),\n",
    "                          order=0,\n",
    "                          anti_aliasing=False,\n",
    "                          preserve_range=True),\n",
    "\n",
    "    # Normalizing\n",
    "    FunctionWrapperDouble(normalize,input=True,target=False),\n",
    "\n",
    "    # Smooth it out \n",
    "    FunctionWrapperDouble(gaussian_smoothing, input=True, target=False, sigma_val=1),\n",
    "\n",
    "    # Contrast enhancement - using histogram equalization\n",
    "    FunctionWrapperDouble(image_histogram_equalization,input=True,target=False),\n",
    "    \n",
    "    # Ensure target segmented images are dense\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The big Hyperparameter tuning loop!\n",
    "This loop is configured to save the loss and validation outputs from each run in order to later be analyzed. We are grabbing the data differently here then we are in the actual training. Due to the smaller nature of the hyperparameter tuning, we are going to load the data beforehand before applying. Here we are gathering about 200 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- Get image data ------------\n",
    "df_image = grab_data(folder_name= 'training/camera_image/', max_parquet = 3)\n",
    "\n",
    "# --------- Get segmented data ----------\n",
    "df_seg = grab_data(folder_name= 'training/camera_segmentation/', max_parquet = 3)\n",
    "\n",
    "# The merged dataframe\n",
    "df_tot = pd.merge(df_image,df_seg,on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "df_tot = df_tot.sample(200, ignore_index=True)\n",
    "\n",
    "print(\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "\n",
    "# Help clear up some space\n",
    "del df_image\n",
    "del df_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some loss functions and other hyperparameters to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions you want to try\n",
    "loss_functions = {\n",
    "    \"DiceLoss\" : dice_loss,\n",
    "    \"CrossEntropyLoss\": nn.CrossEntropyLoss(),\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss(),\n",
    "}\n",
    "\n",
    "# Define different hyperparameter settings to try\n",
    "hyperparameters = {\n",
    "    \"lr\": [0.0001,0.001],\n",
    "    \"batch_size\": [2,6,12],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)\n",
    "n_val = int(len(dataset) * 0.1)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "best_loss = float(\"inf\")\n",
    "best_loss_function = None\n",
    "best_hyperparameters = None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "results = []\n",
    "\n",
    "# Loop for Loss functions\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "  # Loop for Learning Rate\n",
    "  for lr in hyperparameters[\"lr\"]:\n",
    "    # Loop for Batch Size\n",
    "    for batch_size in hyperparameters[\"batch_size\"]:\n",
    "      # Now we're running!\n",
    "      print(\"Running \"+loss_name+\" with loss rate of \",lr,\"with batch size\",batch_size)\n",
    "\n",
    "      # put the training and validation data into each dataloader\n",
    "      training_dataloader = data.DataLoader(dataset=train_set,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "      validation_dataloader = data.DataLoader(dataset=val_set,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "\n",
    "      # Create our model instance, optimizer, and loss function\n",
    "      model = build_unet(num_classes=1, device=device).to(device)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "      criterion = loss_function\n",
    "\n",
    "      # Initialize the GradScaler for mixed-precision training\n",
    "      scaler = GradScaler()\n",
    "\n",
    "      loss_per_epoch = []\n",
    "      #Epoch Loop\n",
    "      for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, (inputs, labels, mask) in enumerate(training_dataloader):\n",
    "          batch_start_time = time.time()\n",
    "\n",
    "          # Move inputs and labels to the GPU\n",
    "          if device.type == 'cuda':\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            mask = mask.to(device, dtype=torch.float32)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Analyze the number of classes in the current segmentation mask\n",
    "          num_classes = analyze_num_classes(labels)\n",
    "\n",
    "          # Update the model's output layer to have the correct number of channels (classes)\n",
    "          model.output_layer = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
    "\n",
    "          # Add nn.Parameter for bias with the desired precision\n",
    "          model.output_layer.bias = nn.Parameter(torch.zeros(num_classes, dtype=torch.float32, device=device))\n",
    "\n",
    "          # Use autocast to perform mixed-precision training\n",
    "          with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs*mask, labels*mask)\n",
    "            #loss_per_epoch.append(loss.item())\n",
    "\n",
    "          scaler.scale(loss).backward()\n",
    "          scaler.step(optimizer)\n",
    "          scaler.update()\n",
    "\n",
    "          # Calculate batch time\n",
    "          batch_time = time.time() - batch_start_time\n",
    "          total_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        average_loss = total_loss / len(training_dataloader)\n",
    "        loss_per_epoch.append(average_loss)\n",
    "        # End time for the epoch\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        #Print progress with batch and epoch times\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "        ## ------------ end of current epoch ---------------\n",
    "\n",
    "        ## - ----------- eval ------------------------------\n",
    "        model.eval() # set to eval mode\n",
    "        total_val_loss = 0.0\n",
    "        eval_loss_list = []\n",
    "        with torch.no_grad():\n",
    "          for val_batch_idx, (val_inputs, val_labels,val_mask) in enumerate(validation_dataloader):\n",
    "            # Move validation inputs and labels to the same device as the model\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_mask = val_mask.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            val_outputs = model(val_inputs)\n",
    "\n",
    "            #Compute the validation loss\n",
    "            if loss_name == 'CrossEntropyLoss':\n",
    "              val_labels_indices = (val_labels*val_mask).argmax(dim=1)\n",
    "              val_loss = criterion(val_outputs*val_mask, val_labels_indices)\n",
    "            else:\n",
    "              val_loss = criterion(val_outputs*val_mask, val_labels*val_mask)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        # Calculate the average validation loss\n",
    "        average_val_loss = total_val_loss / len(validation_dataloader)\n",
    "        eval_loss_list.append(average_val_loss)\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "      # Update best hyperparameters if current loss is better\n",
    "      if average_loss < best_loss and average_loss >= 0: #we don't want super big negatives\n",
    "        best_loss = average_loss\n",
    "        best_loss_function = loss_name\n",
    "        best_hyperparameters = {\"lr\": lr, \"batch_size\": batch_size}\n",
    "\n",
    "      # Save hyperparameter tuning information and loss\n",
    "      result = {\n",
    "          \"Loss Function\": loss_name,\n",
    "          \"Learning Rate\": lr,\n",
    "          \"Batch Size\": batch_size,\n",
    "          \"Loss per Epoch\": loss_per_epoch,\n",
    "          \"Validation Loss per Epoch\": eval_loss_list\n",
    "      }\n",
    "      results.append(result)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Saving all of Information\")\n",
    "results_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/hyperparam_tuning_FINAL.csv\", index=False)\n",
    "print(f\"Best loss function: {best_loss_function}\")\n",
    "print(f\"Best hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, we graph\n",
    "Graphing with Altair involves configuring our results dataframe a little bit before going ahead and applying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = []\n",
    "for _ in results_df['Loss per Epoch']:\n",
    "  epoch_num.append(range(num_epochs))\n",
    "\n",
    "results_df['Epoch_Num'] = epoch_num\n",
    "\n",
    "results_df = results_df.explode(['Loss per Epoch','Epoch_Num']).reset_index(drop=True)\n",
    "\n",
    "alt.Chart(results_df).mark_line().encode(\n",
    "    x = 'Epoch_Num:N',\n",
    "    y = 'Loss per Epoch:Q',\n",
    "    color = 'Batch Size:N',\n",
    ").properties(\n",
    "    width = 180,\n",
    "    height = 180\n",
    ").facet(\n",
    "    column ='Loss Function:N',\n",
    "    row ='Learning Rate:N'\n",
    ").resolve_scale(\n",
    "    y = 'independent',\n",
    "    x = 'independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to Train\n",
    "Firstly, we want to define the use of GPU as well as our preferred hyperparameters. The GPU was set in our hyperparameter tuning loop, but it doesn't hurt to double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to run off of GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Set hyperparameters\n",
    "hyperparameters = {\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 6,\n",
    "    'loss_function': dice_loss,\n",
    "    'parquets': 1,\n",
    "    'num_epochs' : 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the model instance and train as followed, iteratively going through each parquet file from the WAYMO perception bucket.\n",
    "Checkpoints are built in and print statements so that in case something occurs, the current model state is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the model\n",
    "model = build_unet(num_classes=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay = 0.01)\n",
    "criterion = hyperparameters['loss_function']\n",
    "\n",
    "# Initialize the GradScaler for mixed-precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "# Initialize the data to iterate through\n",
    "df_image = grab_data_image()\n",
    "df_seg = grab_data_segment()\n",
    "\n",
    "# to hold our results\n",
    "results = []\n",
    "\n",
    "i = 0\n",
    "# Iterating through data\n",
    "while i < hyperparameters['parquets']:\n",
    "    i += 1\n",
    "\n",
    "    print(\"Loaded parquet\",i)\n",
    "    # The merged dataframe\n",
    "    df_tot = pd.merge(next(df_image),next(df_seg),on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "\n",
    "    print(\"Iteration\",i,\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "    df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "\n",
    "    training_dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)\n",
    "    ## ----- Training loop -----------\n",
    "    training_dataloader = data.DataLoader(dataset=training_dataset,\n",
    "                                      batch_size=hyperparameters['batch_size'],\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "\n",
    "    loss_per_epoch = []\n",
    "    for epoch in range(hyperparameters['num_epochs']):\n",
    "        loss_per_epoch = []\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (inputs, labels, mask) in enumerate(training_dataloader):\n",
    "            \n",
    "            # Move inputs and labels to the GPU\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                mask = mask.to(device, dtype=torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Analyze the number of classes in the current segmentation mask\n",
    "            num_classes = analyze_num_classes(labels)\n",
    "            # Update the model's output layer to have the correct number of channels (classes)\n",
    "            model.output_layer = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
    "            # Add nn.Parameter for bias with the desired precision\n",
    "            model.output_layer.bias = nn.Parameter(torch.zeros(num_classes, dtype=torch.float32, device=device))\n",
    "\n",
    "            # Use autocast to perform mixed-precision training\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.to(outputs.dtype)\n",
    "                loss = criterion(outputs*mask, labels*mask)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        # Calculate average loss for the epoch\n",
    "        average_loss = total_loss / len(training_dataloader)\n",
    "        loss_per_epoch.append(average_loss)\n",
    "        # End time for the epoch\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        #Print progress with batch and epoch times\n",
    "        print(f\"Epoch [{epoch + 1}/{hyperparameters['num_epochs']}], Loss: {average_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    result = {\n",
    "        \"Loss per Epoch\": loss_per_epoch\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    checkpoint = {\n",
    "        'Parquet':i,\n",
    "        'model_state_dict':model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss' : loss_per_epoch\n",
    "    }\n",
    "    checkpoint_path = f'checkpoint_iteration_{i}.pth'\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f'Checkpoint saved at iteration {i}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is all good and done, we go ahead and save our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'/content/drive/MyDrive/Colab Notebooks/unet_model_waymo.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
