{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering and UNet model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "from google.cloud import storage\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "import ipyplot\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers import Concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from skimage.io import imread\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision.transforms.functional import pad\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from transforms import (\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    "    normalize,\n",
    ")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing data from Google bucket\n",
    "First, we want to set up credentials and the client,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### google bucket pre sets for data\n",
    "google_application_credentials = '/content/drive/MyDrive/Colab Notebooks/food-V2.json'\n",
    "bucket_name = 'waymo_perception_data' #you need to name your bucket\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_application_credentials\n",
    "client = storage.Client()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we iterate through two different folders of information. One being the camera images and the other being the segmented image. For memory ease, we only iterate through some of the files. Finally, we merge based on some key information so that each image is connected with its appropiate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- Get image data ------------\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "df_image = pd.DataFrame()\n",
    "folder_name = 'training/camera_image/'\n",
    "i = -1\n",
    "\n",
    "for blob in  bucket.list_blobs(prefix=folder_name):\n",
    "  i += 1\n",
    "  object_name = blob.name[len(folder_name):]\n",
    "  temp = \"temp_file.parquet\"\n",
    "  content = blob.download_to_filename(temp)\n",
    "  df = pd.read_parquet(temp)\n",
    "  if df_image.empty:\n",
    "    df_image = df\n",
    "  else:\n",
    "    df_image = pd.concat([df_image,df])\n",
    "  if i == 9:\n",
    "    break\n",
    "\n",
    "\n",
    "# --------- Get segmented data ----------\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "df_seg = pd.DataFrame()\n",
    "i = -1\n",
    "for blob in  bucket.list_blobs(prefix='training/camera_segmentation/'):\n",
    "  i += 1\n",
    "  object_name = blob.name[len(folder_name):]\n",
    "  temp = \"temp_file.parquet\"\n",
    "  content = blob.download_to_filename(temp)\n",
    "  df = pd.read_parquet(temp)\n",
    "  if df_seg.empty:\n",
    "    df_seg = df\n",
    "  else:\n",
    "    df_seg = pd.concat([df_seg,df])\n",
    "  if i == 9:\n",
    "    break\n",
    "  \n",
    "# The merged dataframe\n",
    "df_tot = pd.merge(df_image,df_seg,on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "df_tot = df_tot.sample(100, ignore_index=True)\n",
    "\n",
    "print(\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "\n",
    "# Help clear up some space\n",
    "del df_image\n",
    "del df_seg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the images to see that the dataframes merged correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(BytesIO(df_tot['image'][3]))\n",
    "print(img.format,img.size,img.mode)\n",
    "seg = Image.open(BytesIO(df_tot['seg_label'][3]))\n",
    "print(seg.format,seg.size,seg.mode)\n",
    "\n",
    "# display images\n",
    "ipyplot.plot_images([img,seg], max_images=2, img_width=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET Model and Helper Functions\n",
    "UNet is a type of CNN neural network that works well with small batches of images for segmentation tasks. First, we are going to transform the data to best work with pytorch. A custom collate function is used in the case of uneven tensors being input into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataSet(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 inputs: list,\n",
    "                 targets: list,\n",
    "                 transform=None\n",
    "                 ):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    index: int):\n",
    "        # Select the sample\n",
    "        input_ID = self.inputs[index]\n",
    "        target_ID = self.targets[index]\n",
    "\n",
    "        # Load input and target\n",
    "        x = np.array(Image.open(BytesIO(input_ID)))\n",
    "        y = np.array(Image.open(BytesIO(target_ID)))\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "# Custom collate function to handle varying tensor sizes\n",
    "def custom_collate(batch):\n",
    "    # Get the maximum height and width in the current batch\n",
    "    max_height = max([img.shape[1] for img, _ in batch])\n",
    "    max_width = max([img.shape[2] for img, _ in batch])\n",
    "\n",
    "    # Pad or resize images and labels to the maximum size\n",
    "    padded_images = []\n",
    "    padded_labels = []\n",
    "    for img, label in batch:\n",
    "        img_padded = pad(img, padding= (0, max_width - img.shape[2], 0, max_height - img.shape[1]), fill=0)\n",
    "        label_padded = pad(label, padding = (0, max_width - label.shape[1], 0, max_height - label.shape[0]), fill=255)\n",
    "\n",
    "        label_padded = label_padded.unsqueeze(0)\n",
    "\n",
    "        padded_images.append(img_padded)\n",
    "        padded_labels.append(label_padded)\n",
    "\n",
    "\n",
    "\n",
    "    # Stack the padded images and labels into a batch\n",
    "    batch_images = torch.stack(padded_images, dim=0)\n",
    "    batch_labels = torch.stack(padded_labels, dim=0)\n",
    "\n",
    "    return batch_images, batch_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply a pipeline of transformations to the training data. This is to help prevent data leakage, as well as streamline our process. We resize the images to be smaller in order to prevent any memory issues when developing our model. \n",
    "\n",
    "Consider adding more transformations in order to add robustness to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "transforms = ComposeDouble([\n",
    "        FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(640, 960, 3)),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(640, 960),\n",
    "                          order=0,\n",
    "                          anti_aliasing=False,\n",
    "                          preserve_range=True),\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize),\n",
    "\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to do a check to see if our SegmentationDataSet and transforms works well and can be fed into a dataloader, alongside our custom collate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)\n",
    "\n",
    "training_dataloader = data.DataLoader(dataset=training_dataset,\n",
    "                                      batch_size=2,\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(training_dataloader))\n",
    "\n",
    "# [N,C,H,W], [N,H,W]\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell block can be run multiple times in order to give a preview of the transformed data.\n",
    "\n",
    "### Developing the UNet model archecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.outputs = nn.Conv2d(64, self.num_classes, kernel_size=1, padding=0) #for dynamic classes\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created own loss function and set up variables for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(predicted, target):\n",
    "    smooth = 1.0  # Smoothing factor to avoid division by zero\n",
    "    intersection = torch.sum(predicted * target)\n",
    "    union = torch.sum(predicted) + torch.sum(target)\n",
    "    dice_coefficient = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return 1.0 - dice_coefficient\n",
    "# Define the loss functions you want to try\n",
    "loss_functions = {\n",
    "    #already did dice loss\n",
    "    \"DiceLoss\" : dice_loss,\n",
    "    \"CrossEntropyLoss\": nn.CrossEntropyLoss(),\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss(),\n",
    "}\n",
    "\n",
    "# Define different hyperparameter settings to try\n",
    "hyperparameters = {\n",
    "    \"lr\": [0.001, 0.01, 0.0001],\n",
    "    \"batch_size\": [2, 4, 8],\n",
    "}\n",
    "\n",
    "training_dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning loop - optimized to have results saved to google drive for furture analysis as well as optimize GPU memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_loss_function = None\n",
    "best_hyperparameters = None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "  results = []\n",
    "  for lr in hyperparameters[\"lr\"]:\n",
    "    for batch_size in hyperparameters[\"batch_size\"]:\n",
    "      \n",
    "      training_dataloader = data.DataLoader(dataset=training_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "\n",
    "      model = build_unet(num_classes=1).to(device)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "      criterion = loss_function\n",
    "      # Initialize the GradScaler for mixed-precision training\n",
    "      scaler = GradScaler()\n",
    "\n",
    "      #Epoch Loop\n",
    "      for epoch in range(num_epochs):\n",
    "        loss_per_epoch = []\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(training_dataloader):\n",
    "          batch_start_time = time.time()\n",
    "\n",
    "          # Move inputs and labels to the GPU\n",
    "          if device.type == 'cuda':\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Use autocast to perform mixed-precision training\n",
    "          \n",
    "          with autocast():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            labels = labels.to(outputs.dtype)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_per_epoch.append(loss)\n",
    "\n",
    "          scaler.scale(loss).backward()\n",
    "          scaler.step(optimizer)\n",
    "          scaler.update()\n",
    "\n",
    "          # Calculate batch time\n",
    "          batch_time = time.time() - batch_start_time\n",
    "          total_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        average_loss = total_loss / len(training_dataloader)\n",
    "        # End time for the epoch\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "    \n",
    "        #Print progress with batch and epoch times\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "      # Update best hyperparameters if current loss is better\n",
    "      if average_loss < best_loss:\n",
    "        best_loss = average_loss\n",
    "        best_loss_function = loss_name\n",
    "        best_hyperparameters = {\"lr\": lr, \"batch_size\": batch_size}\n",
    "\n",
    "      # Save hyperparameter tuning information and loss\n",
    "      result = {\n",
    "          \"Loss Function\": loss_name,\n",
    "          \"Learning Rate\": lr,\n",
    "          \"Batch Size\": batch_size,\n",
    "          \"Loss per Epoch\": loss_per_epoch,\n",
    "      }\n",
    "      results.append(result)\n",
    "\n",
    "  # Convert the results list to a DataFrame\n",
    "  results_df = pd.DataFrame(results)\n",
    "\n",
    "  #  Save the results to a CSV file\n",
    "  str_name = loss_name + \"hyperparameter_tuning_results.csv\"\n",
    "  print(\"Saving all of \"+loss_name)\n",
    "  results_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/\"+str_name, index=False)\n",
    "print(f\"Best loss function: {best_loss_function}\")\n",
    "print(f\"Best hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
